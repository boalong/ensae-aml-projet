{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "cef03b37-5821-4c55-abbd-d271b8fa6a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5ace334-3c2b-4895-b49d-a0dc82c5886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "188aa57c-7054-400f-a1ff-fb2b1276a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from string import digits\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "80f04f23-985f-41bb-8ae1-1ee95c259fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LSTM for each file and store results for hyperparameter combinations\n",
    "train_dir = sorted([f for f in os.listdir(\"../training_data/test-and-training/training_data/\") if f.endswith('xlsx')])\n",
    "test_dir = sorted([f for f in os.listdir(\"../training_data/test-and-training/test_data/\") if f.endswith('xlsx')])\n",
    "remove_digits = str.maketrans('', '', digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6814c1f3-7405-4a58-ac2b-a22dd01d9652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lab-manual-split-combine-train-5768.xlsx',\n",
       " 'lab-manual-split-combine-train-78516.xlsx',\n",
       " 'lab-manual-split-combine-train-944601.xlsx']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6877bf82-db50-4bd0-9075-310dae3b8c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lab-manual-split-combine-test-5768.xlsx',\n",
       " 'lab-manual-split-combine-test-78516.xlsx',\n",
       " 'lab-manual-split-combine-test-944601.xlsx']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "64d17c91-999d-410a-9ce7-e6f81ec36c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Number:  0\n",
      "lab-manual-split-combine-5768\n",
      "5768\n",
      "lab-manual-split-combine\n"
     ]
    }
   ],
   "source": [
    "for f in range(len(train_dir[:1])): # on ne s'intéresse que aux fichiers split-combine (le plus général, données de meilleure qualité)\n",
    "    print(\"Experiment Number: \", f)\n",
    "    name = train_dir[f].replace(\".xlsx\", \"\").replace(\"-train\", \"\")\n",
    "    seed = int(re.findall(\"\\d+\", name)[0])\n",
    "    base_name = name.translate(remove_digits)[:-1]\n",
    "    print(name), print(seed), print(base_name)\n",
    "\n",
    "    train = pd.read_excel(\"../training_data/test-and-training/training_data/\" + train_dir[f], index_col=False)\n",
    "    test = pd.read_excel(\"../training_data/test-and-training/test_data/\" + test_dir[f], index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ec0f6c9e-9f5f-4662-8ba0-521a3a1f39f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "      <th>orig_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>Our mandate, sorry, is price inflation.</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224</td>\n",
       "      <td>During the past several years, workers across ...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>861</td>\n",
       "      <td>The Committee's assessments will take into acc...</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>Although real growth was likely to be moderate...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>914</td>\n",
       "      <td>The increase over the last few months in five-...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>429</td>\n",
       "      <td>Indeed, the members did not rule out the emerg...</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>461</td>\n",
       "      <td>In the simplest version of his model, Bill ass...</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>797</td>\n",
       "      <td>The implication is that trend productivity and...</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>913</td>\n",
       "      <td>The hurricanes were also expected to depress p...</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>578</td>\n",
       "      <td>Moreover, when some measures of inflation were...</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1984 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                           sentence  year  label  \\\n",
       "0       183            Our mandate, sorry, is price inflation.  2021      1   \n",
       "1       224  During the past several years, workers across ...  2000      1   \n",
       "2       861  The Committee's assessments will take into acc...  2004      2   \n",
       "3        59  Although real growth was likely to be moderate...  2000      1   \n",
       "4       914  The increase over the last few months in five-...  2000      1   \n",
       "...     ...                                                ...   ...    ...   \n",
       "1979    429  Indeed, the members did not rule out the emerg...  2016      0   \n",
       "1980    461  In the simplest version of his model, Bill ass...  2021      2   \n",
       "1981    797  The implication is that trend productivity and...  2004      0   \n",
       "1982    913  The hurricanes were also expected to depress p...  2000      2   \n",
       "1983    578  Moreover, when some measures of inflation were...  2021      0   \n",
       "\n",
       "      orig_index  \n",
       "0            178  \n",
       "1            220  \n",
       "2            812  \n",
       "3             59  \n",
       "4            864  \n",
       "...          ...  \n",
       "1979         412  \n",
       "1980         447  \n",
       "1981         774  \n",
       "1982         863  \n",
       "1983         560  \n",
       "\n",
       "[1984 rows x 5 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "29989858-9097-41f3-8824-4f79da1f6b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "      <th>orig_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>871</td>\n",
       "      <td>The U. S. international trade deficit narrowed...</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123</td>\n",
       "      <td>Based on historical experience, it seems impro...</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>903</td>\n",
       "      <td>This was also an era when the principal mortga...</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>875</td>\n",
       "      <td>The available data for October suggested that ...</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>351</td>\n",
       "      <td>However, we have also found that excluding vol...</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>654</td>\n",
       "      <td>Over the medium term, participants expected st...</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>373</td>\n",
       "      <td>If so, GDP growth this calendar year could be ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>760</td>\n",
       "      <td>Several participants discussed the possible co...</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>168</td>\n",
       "      <td>Looking ahead, FOMC participants project the u...</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>493</td>\n",
       "      <td>Inflation Targeting and Central Bank Behavior,...</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                           sentence  year  label  \\\n",
       "0      871  The U. S. international trade deficit narrowed...  2010      0   \n",
       "1      123  Based on historical experience, it seems impro...  2007      0   \n",
       "2      903  This was also an era when the principal mortga...  2004      2   \n",
       "3      875  The available data for October suggested that ...  2009      2   \n",
       "4      351  However, we have also found that excluding vol...  2006      2   \n",
       "..     ...                                                ...   ...    ...   \n",
       "491    654  Over the medium term, participants expected st...  2012      0   \n",
       "492    373  If so, GDP growth this calendar year could be ...  2006      1   \n",
       "493    760  Several participants discussed the possible co...  2010      1   \n",
       "494    168  Looking ahead, FOMC participants project the u...  2012      2   \n",
       "495    493  Inflation Targeting and Central Bank Behavior,...  2021      2   \n",
       "\n",
       "     orig_index  \n",
       "0           822  \n",
       "1           122  \n",
       "2           876  \n",
       "3           826  \n",
       "4           342  \n",
       "..          ...  \n",
       "491         620  \n",
       "492         363  \n",
       "493         719  \n",
       "494         163  \n",
       "495         477  \n",
       "\n",
       "[496 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b27d81-f066-4212-8e84-fbdee85c3e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f4708f7a-fa3e-45be-b223-64188bfdf191",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['sentence'].tolist()\n",
    "Y_train = torch.tensor(train['label'].to_numpy(), dtype=torch.int)\n",
    "\n",
    "X_test = test['sentence'].tolist()\n",
    "Y_test = torch.tensor(test['label'].to_numpy(), dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fe88da81-521b-4ace-9f3a-2d77389627a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "tokenized_train = [tokenizer(doc) for doc in X_train]\n",
    "tokenized_test = [tokenizer(doc) for doc in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "13a85ec1-2fbb-4243-a260-4340a43e4e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_freq = Counter([tok for doc in tokenized_train for tok in doc])\n",
    "vocab = tok_freq.most_common(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9d44ea67-e11b-4573-b43a-cf5f0b8a51b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {\"<pad>\": 0, \"<oov>\": 1}\n",
    "index=2\n",
    "for word, freq in vocab:\n",
    "    vocab_dict[word] = index\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b4abe99b-2e72-4e6b-bcb9-9a8e43fe55cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_indices(text):\n",
    "    tokens = tokenizer(text)\n",
    "    indices = [vocab_dict.get(token, vocab_dict[\"<oov>\"]) for token in tokens]\n",
    "    return torch.tensor(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2414977e-6997-47d7-8b2a-67f1eeb3ce5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1984, 209]), torch.Size([496, 177]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_train = [text_to_indices(text) for text in X_train]\n",
    "indices_test = [text_to_indices(text) for text in X_test]\n",
    "padded_indices_train = pad_sequence(indices_train, batch_first=True)\n",
    "padded_indices_test = pad_sequence(indices_test, batch_first=True)\n",
    "padded_indices_train.shape, padded_indices_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "72a61336-caa4-4e27-8aaa-a7e95b590312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1984, 100]), torch.Size([496, 100]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_indices_train = padded_indices_train[:, :100] # truncate\n",
    "padded_indices_test = padded_indices_test[:, :100] # truncate\n",
    "padded_indices_train.shape, padded_indices_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4efce49e-3681-49f2-b7de-193d98e52348",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_docs_array_train = padded_indices_train\n",
    "my_docs_array_test = padded_indices_test\n",
    "\n",
    "my_labels_array_train = Y_train\n",
    "my_labels_array_test = Y_test\n",
    "\n",
    "# load dictionary of word indexes (sorted by decreasing frequency across the corpus)\n",
    "word_to_index = vocab_dict\n",
    "\n",
    "# invert mapping\n",
    "index_to_word = {v: k for k, v in word_to_index.items()} ### fill the gap (use a dict comprehension) ###\n",
    "input_size = my_docs_array_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777f3ec-36a4-4776-8e1f-97320ab6e610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "598cbf48-ecdb-4491-88d0-b5b1cd4c0b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le nettoyage est terminé, on peut passer au modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2bd1549a-ebdc-4bde-b1ff-72beab0be9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(nn.Module):\n",
    "    \"\"\"\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape, return_coefficients=False, bias=True):\n",
    "        super(AttentionWithContext, self).__init__()\n",
    "        self.return_coefficients = return_coefficients\n",
    "\n",
    "        self.W = nn.Linear(input_shape, input_shape, bias=bias)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.u = nn.Linear(input_shape, 1, bias=False)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.W.weight.data.uniform_(-initrange, initrange)\n",
    "        self.W.bias.data.uniform_(-initrange, initrange)\n",
    "        self.u.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        # do not pass the mask to the next layers\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = (\n",
    "            mask.float()\n",
    "            .masked_fill(mask == 0, float(\"-inf\"))\n",
    "            .masked_fill(mask == 1, float(0.0))\n",
    "        )\n",
    "        return mask\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        uit = self.W(x) # fill the gap # compute uit = W . x  where x represents ht\n",
    "        uit = self.tanh(uit)\n",
    "        ait = self.u(uit)\n",
    "        a = torch.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            a = a*mask.double()\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        eps = 1e-9\n",
    "        a = a / (torch.sum(a, axis=1, keepdim=True) + eps)\n",
    "        weighted_input = a * x # computes the attentional vector\n",
    "        if self.return_coefficients:\n",
    "            return [torch.sum(weighted_input, axis=1), a] ### [attentional vector, coefficients] ###\n",
    "        else:\n",
    "            return torch.sum(weighted_input, axis=1) ### attentional vector only ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d4f01d28-0b57-4a5b-9084-c0fd700d7692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "d = 30 # dimensionality of word embeddings\n",
    "n_units = 50 # RNN layer dimensionality\n",
    "drop_rate = 0.5 # dropout\n",
    "mfw_idx = 2 # index of the most frequent words in the dictionary\n",
    "padding_idx = 0 # 0 is for the special padding token\n",
    "oov_idx = 1 # 1 is for the special out-of-vocabulary token\n",
    "batch_size = 64\n",
    "nb_epochs = 50\n",
    "my_patience = 5 # for early stopping strategy\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "19ed2041-0db2-48a8-8d27-35d1c107c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.documents = x\n",
    "        self.labels = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.documents)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        document = self.documents[index]\n",
    "        label = self.labels[index]\n",
    "        sample = {\n",
    "            \"document\": torch.tensor(document),\n",
    "            \"label\": torch.tensor(label),\n",
    "            }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "fb7aea23-c679-47c6-8d2f-e4f53238c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(x, y, batch_size=32):\n",
    "    dataset = Dataset_(x, y)\n",
    "    data_loader = DataLoader(dataset=dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=True,\n",
    "                            )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "8977f23a-5f30-4039-992e-2fe7e9c74d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBiGRU(nn.Module):\n",
    "    def __init__(self, input_shape, n_units, index_to_word, dropout=0):\n",
    "        super(AttentionBiGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(index_to_word), # vocab size\n",
    "                                      d, # dimensionality of embedding space\n",
    "                                      padding_idx=0)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "        self.gru = nn.GRU(input_size=d,\n",
    "                          hidden_size=n_units,\n",
    "                          num_layers=1,\n",
    "                          bias=True,\n",
    "                          batch_first=True,\n",
    "                          bidirectional=True)\n",
    "        self.attention = AttentionWithContext(n_units * 2,   # the input shape for the attention layer\n",
    "                                              return_coefficients=True)\n",
    "        self.lin_out = nn.Linear(n_units * 2,   # the input size of the last linear layer\n",
    "                                 3)\n",
    "        self.preds = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, sent_ints):\n",
    "        sent_wv = self.embedding(sent_ints)\n",
    "        sent_wv_dr = self.dropout(sent_wv)\n",
    "        sent_wa, _ = self.gru(sent_wv_dr) # RNN layer\n",
    "        sent_att_vec, word_att_coeffs = self.attention(sent_wa) # attentional vector for the sent\n",
    "        sent_att_vec_dr = self.dropout(sent_att_vec)\n",
    "        logits = self.lin_out(sent_att_vec_dr)\n",
    "        return self.preds(logits), word_att_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "5c0aefc9-2196-455b-bdaf-747727691d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_loader, verbose=True):\n",
    "    model.eval()\n",
    "    ncorrect = ntotal = 0\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(data_loader):\n",
    "            # inference\n",
    "            output = model(data[\"document\"].to(device))[0]\n",
    "            label = data[\"label\"].to(device)\n",
    "            label = label.long()\n",
    "            loss = criterion(output, label)\n",
    "            # total number of examples\n",
    "            ntotal += output.shape[0]\n",
    "            # number of correct predictions\n",
    "            predictions = torch.argmax(output, dim=1)\n",
    "            ncorrect += torch.sum(predictions == label) #fill me # number of correct prediction - hint: use torch.sum\n",
    "            losses.append(loss.item())\n",
    "        acc = ncorrect / ntotal\n",
    "        avg_loss = np.mean(losses)\n",
    "        if verbose:\n",
    "          print(\"validation loss: {:.4f}, validation accuracy: {:3.2f}\".format(loss, acc*100))\n",
    "        return avg_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "81bb7b7d-3f16-4148-8f7b-eedc3ddd71ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentionBiGRU(input_size, n_units, index_to_word).to(device)\n",
    "model = model.double()\n",
    "lr = 0.01  # learning rate\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) # Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f239b94e-fcb6-40d4-a0bd-84fe7881b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train=my_docs_array_train,\n",
    "          y_train=my_labels_array_train,\n",
    "          x_test=my_docs_array_test,\n",
    "          y_test=my_labels_array_test,\n",
    "          word_dict=index_to_word,\n",
    "          batch_size=batch_size):\n",
    "\n",
    "    train_data = get_loader(x_train, y_train, batch_size)\n",
    "    test_data = get_loader(x_test, y_test, batch_size)\n",
    "\n",
    "    best_test_loss = np.inf\n",
    "    p = my_patience # patience\n",
    "\n",
    "    for epoch in range(1, nb_epochs + 1):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        with tqdm(train_data, unit=\"batch\") as tepoch:\n",
    "    \n",
    "            for idx, data in enumerate(tepoch):\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                input = data['document'].to(device)\n",
    "                label = data['label'].to(device)\n",
    "                label = label.long()\n",
    "                output = model.forward(input)[0]\n",
    "                loss = criterion(output, label) # fill the gap # compute the loss\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient\n",
    "                optimizer.step()\n",
    "\n",
    "                losses.append(loss.item())\n",
    "                accuracy = torch.sum(torch.argmax(output, dim=1) == label).item() / batch_size\n",
    "                accuracies.append(accuracy)\n",
    "                tepoch.set_postfix(loss=sum(losses)/len(losses), accuracy=100. * sum(accuracies)/len(accuracies))\n",
    "\n",
    "        # train_acc = evaluate_accuracy(train_data, False)\n",
    "        test_loss, test_acc = evaluate_accuracy(test_data, False)\n",
    "        print(\"===> Epoch {} Complete: Validation Loss: {:.4f}, Validation Accuracy: {:3.2f}%\"\n",
    "              .format(epoch, test_loss, 100.*test_acc))\n",
    "        if test_loss <= best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            print(\"Validation loss improved, saving model...\")\n",
    "            torch.save(model.state_dict(), './best_model.pt')\n",
    "            p = 0\n",
    "            print()\n",
    "        else:\n",
    "            p += 1\n",
    "            if p==my_patience:\n",
    "                print(\"Validation loss did not improve for {} epochs, stopping training...\".format(my_patience))\n",
    "                break\n",
    "    print(\"Loading best checkpoint...\")\n",
    "    model.load_state_dict(torch.load('./best_model.pt'))\n",
    "    model.eval()\n",
    "    print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "b6b27bbe-6e44-4ddf-8fad-2b5d3526751e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6376/728418263.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"document\": torch.tensor(document),\n",
      "/tmp/ipykernel_6376/728418263.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"label\": torch.tensor(label),\n",
      "Epoch 1: 100%|██████████| 31/31 [01:33<00:00,  3.03s/batch, accuracy=48.3, loss=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 1 Complete: Validation Loss: 1.0471, Validation Accuracy: 49.11%\n",
      "Validation loss improved, saving model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 31/31 [01:27<00:00,  2.83s/batch, accuracy=49.4, loss=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 2 Complete: Validation Loss: 1.0437, Validation Accuracy: 49.78%\n",
      "Validation loss improved, saving model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 31/31 [01:29<00:00,  2.88s/batch, accuracy=50.3, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 3 Complete: Validation Loss: 1.0250, Validation Accuracy: 49.55%\n",
      "Validation loss improved, saving model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 31/31 [01:27<00:00,  2.84s/batch, accuracy=50.3, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 4 Complete: Validation Loss: 1.0090, Validation Accuracy: 48.66%\n",
      "Validation loss improved, saving model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 31/31 [01:25<00:00,  2.75s/batch, accuracy=53.9, loss=0.98] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 5 Complete: Validation Loss: 0.9955, Validation Accuracy: 51.79%\n",
      "Validation loss improved, saving model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 31/31 [01:22<00:00,  2.67s/batch, accuracy=58.2, loss=0.949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 7 Complete: Validation Loss: 1.0086, Validation Accuracy: 50.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 31/31 [01:26<00:00,  2.79s/batch, accuracy=59.6, loss=0.932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 8 Complete: Validation Loss: 0.9959, Validation Accuracy: 50.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 31/31 [01:25<00:00,  2.77s/batch, accuracy=61.8, loss=0.912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 9 Complete: Validation Loss: 0.9807, Validation Accuracy: 55.58%\n",
      "Validation loss improved, saving model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 31/31 [01:23<00:00,  2.69s/batch, accuracy=64.2, loss=0.894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 10 Complete: Validation Loss: 1.0010, Validation Accuracy: 52.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 31/31 [01:23<00:00,  2.70s/batch, accuracy=67.2, loss=0.868]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 11 Complete: Validation Loss: 1.0025, Validation Accuracy: 51.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 31/31 [01:25<00:00,  2.76s/batch, accuracy=68, loss=0.862]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 12 Complete: Validation Loss: 0.9952, Validation Accuracy: 54.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 31/31 [01:26<00:00,  2.78s/batch, accuracy=71.4, loss=0.829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 13 Complete: Validation Loss: 1.0005, Validation Accuracy: 53.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 31/31 [01:22<00:00,  2.67s/batch, accuracy=69.5, loss=0.846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 14 Complete: Validation Loss: 1.0020, Validation Accuracy: 54.02%\n",
      "Validation loss did not improve for 5 epochs, stopping training...\n",
      "Loading best checkpoint...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "4bf48717-5159-4d57-8212-2c998e588a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "      <th>orig_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>871</td>\n",
       "      <td>The U. S. international trade deficit narrowed...</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123</td>\n",
       "      <td>Based on historical experience, it seems impro...</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>903</td>\n",
       "      <td>This was also an era when the principal mortga...</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>875</td>\n",
       "      <td>The available data for October suggested that ...</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>351</td>\n",
       "      <td>However, we have also found that excluding vol...</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>654</td>\n",
       "      <td>Over the medium term, participants expected st...</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>373</td>\n",
       "      <td>If so, GDP growth this calendar year could be ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>760</td>\n",
       "      <td>Several participants discussed the possible co...</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>168</td>\n",
       "      <td>Looking ahead, FOMC participants project the u...</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>493</td>\n",
       "      <td>Inflation Targeting and Central Bank Behavior,...</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                           sentence  year  label  \\\n",
       "0      871  The U. S. international trade deficit narrowed...  2010      0   \n",
       "1      123  Based on historical experience, it seems impro...  2007      0   \n",
       "2      903  This was also an era when the principal mortga...  2004      2   \n",
       "3      875  The available data for October suggested that ...  2009      2   \n",
       "4      351  However, we have also found that excluding vol...  2006      2   \n",
       "..     ...                                                ...   ...    ...   \n",
       "491    654  Over the medium term, participants expected st...  2012      0   \n",
       "492    373  If so, GDP growth this calendar year could be ...  2006      1   \n",
       "493    760  Several participants discussed the possible co...  2010      1   \n",
       "494    168  Looking ahead, FOMC participants project the u...  2012      2   \n",
       "495    493  Inflation Targeting and Central Bank Behavior,...  2021      2   \n",
       "\n",
       "     orig_index  \n",
       "0           822  \n",
       "1           122  \n",
       "2           876  \n",
       "3           826  \n",
       "4           342  \n",
       "..          ...  \n",
       "491         620  \n",
       "492         363  \n",
       "493         719  \n",
       "494         163  \n",
       "495         477  \n",
       "\n",
       "[496 rows x 5 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f11317db-5d05-4af6-8b43-03fcacde0aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([496, 100])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = get_loader(my_docs_array_test, my_labels_array_test, batch_size)\n",
    "test_data.dataset.documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "586d3354-1bf9-4a2c-bd68-17ba044c3ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.forward(test_data.dataset.documents)\n",
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "bdf47a9a-5e2f-4e75-81cb-71ba651fc16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0400, 0.2400, 0.7300],\n",
       "        [0.0200, 0.0900, 0.8900],\n",
       "        [0.0100, 0.0100, 0.9900],\n",
       "        ...,\n",
       "        [0.8900, 0.1000, 0.0100],\n",
       "        [0.5100, 0.0200, 0.4700],\n",
       "        [0.0000, 0.0000, 1.0000]], dtype=torch.float64,\n",
       "       grad_fn=<RoundBackward1>)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.round(output[0], decimals=2)#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "49a06db1-02d0-4154-bfb6-0b16ff895aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2, 1, 0, 1, 0, 2, 1, 1, 0, 1, 0, 2, 2,\n",
       "        0, 1, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 1, 0, 0, 2, 2, 1, 0, 2, 2, 2, 2, 1,\n",
       "        2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 0, 2, 2, 2,\n",
       "        0, 2, 1, 2, 1, 0, 1, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 0, 2, 0,\n",
       "        2, 0, 2, 0, 1, 2, 0, 1, 2, 2, 0, 0, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 0,\n",
       "        1, 2, 0, 2, 0, 2, 0, 1, 1, 2, 0, 0, 2, 1, 2, 1, 1, 0, 0, 2, 2, 2, 1, 2,\n",
       "        2, 0, 0, 2, 2, 0, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 0, 2, 1, 0, 0, 2,\n",
       "        0, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 0, 0, 2, 2, 2, 0, 2, 0, 2, 1, 2, 2, 2,\n",
       "        2, 0, 0, 1, 2, 2, 2, 0, 1, 1, 2, 2, 0, 2, 1, 1, 0, 2, 2, 1, 2, 2, 2, 0,\n",
       "        0, 2, 2, 0, 1, 2, 1, 0, 0, 1, 1, 1, 0, 1, 2, 2, 1, 2, 2, 2, 1, 2, 0, 2,\n",
       "        2, 2, 1, 1, 2, 1, 2, 2, 0, 1, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2,\n",
       "        2, 2, 0, 1, 1, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 1, 2, 0, 1, 0, 1, 0, 2,\n",
       "        1, 2, 0, 0, 1, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0, 1, 2, 0, 2, 1, 2, 2, 0, 1,\n",
       "        1, 2, 2, 2, 0, 2, 2, 1, 2, 2, 0, 1, 2, 1, 2, 1, 0, 0, 2, 2, 2, 0, 1, 2,\n",
       "        2, 2, 1, 2, 1, 2, 2, 1, 0, 2, 1, 2, 2, 1, 0, 0, 2, 2, 1, 0, 2, 0, 0, 2,\n",
       "        2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 0, 0, 1, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 2,\n",
       "        2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 1, 1, 0, 2, 0, 2, 1, 2, 2, 1, 2, 1, 2, 0,\n",
       "        1, 0, 1, 0, 0, 2, 2, 1, 2, 2, 1, 0, 2, 0, 2, 0, 0, 2, 0, 1, 0, 2, 0, 0,\n",
       "        2, 2, 2, 0, 2, 2, 1, 1, 2, 0, 0, 2, 2, 1, 2, 2, 1, 0, 2, 0, 1, 0, 2, 0,\n",
       "        0, 1, 1, 1, 2, 2, 0, 0, 1, 0, 2, 1, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 1, 0,\n",
       "        1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 1, 1, 2, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "090fabf1-d469-4128-9fb0-f95f8235ce67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 0, 2, 0, 1, 2, 2, 2, 2, 2, 2, 0, 1, 0, 2, 2, 1, 1, 0, 2, 2,\n",
       "        2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 0, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 1, 2, 2, 2, 1, 2, 0, 0,\n",
       "        0, 2, 0, 2, 1, 1, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0,\n",
       "        2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 1, 0, 2, 0, 2, 0, 2, 2, 0,\n",
       "        0, 2, 0, 2, 0, 2, 0, 1, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2,\n",
       "        2, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 0, 0, 2, 2,\n",
       "        2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2,\n",
       "        0, 0, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "        0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 1, 0, 2, 2, 1, 2, 2, 2, 2, 0, 2, 0, 0,\n",
       "        2, 2, 2, 2, 2, 0, 0, 2, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2,\n",
       "        2, 0, 0, 1, 2, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 2, 2, 2, 1, 0, 2, 0, 2,\n",
       "        0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 1, 0, 2, 0, 2,\n",
       "        1, 2, 0, 2, 1, 0, 1, 2, 2, 1, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2,\n",
       "        0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1,\n",
       "        2, 1, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2,\n",
       "        2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 0, 1, 2, 2, 2,\n",
       "        2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 1, 1, 0, 0, 2, 2,\n",
       "        0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0,\n",
       "        2, 1, 1, 2, 2, 0, 0, 0, 0, 2, 1, 2, 0, 2, 2, 2, 1, 0, 0, 2, 2, 2, 0, 0,\n",
       "        2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 0, 2, 2, 0, 0, 2])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(output[0], dim=1) # ça prédit que des 2 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "2d4e63d5-4f15-4f79-b9c3-e49928fcb37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([496, 100, 1])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1].shape # les poids d'attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762cad9c-89df-4ed0-afc8-76c6ae520914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "2c10196e-26f6-4089-a746-0f326fe1eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le score F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "2d2ff6ab-3ab6-4bfc-94f8-b4f6d168c1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0110acb3-3247-4f7e-92f0-2bbd6c3a56a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "56e6473a-b6d0-4800-b783-63c5ca483b31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true = [i.item() for i in list(test_data.dataset.labels)]\n",
    "predicted = [i.item() for i in list(torch.argmax(output[0], dim=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "96c4945f-2210-47f2-bd4b-598c2cc28bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5092636455317361"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(true, predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "4082d53d-e654-459e-a53d-1aa70eaeb2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.47      0.45       129\n",
      "           1       0.50      0.16      0.25       122\n",
      "           2       0.59      0.77      0.67       245\n",
      "\n",
      "    accuracy                           0.54       496\n",
      "   macro avg       0.51      0.47      0.46       496\n",
      "weighted avg       0.53      0.54      0.51       496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb2c44c-29f9-48ab-a24e-89a4a73a3073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment-cpu",
   "language": "python",
   "name": "environment-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
